{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade=cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "recognizer.read(\"recognizer.yml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {}\n",
    "with open(\"names_ids.pickle\", \"rb\") as f:\n",
    "    names_1 = pickle.load(f)\n",
    "    names = {value:key for key,value in names_1.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 315 120 120\n",
      "Alvaro_Uribe\n",
      "360 315 120 120\n",
      "Alvaro_Uribe\n",
      "359 278 125 125\n",
      "Alejandro_Toledo\n",
      "359 278 125 125\n",
      "Alejandro_Toledo\n",
      "356 237 147 147\n",
      "Alvaro_Uribe\n",
      "365 216 152 152\n",
      "Alejandro_Toledo\n",
      "365 216 152 152\n",
      "Alejandro_Toledo\n",
      "379 189 155 155\n",
      "Alejandro_Toledo\n",
      "390 164 152 152\n",
      "Alejandro_Toledo\n",
      "390 164 152 152\n",
      "Alejandro_Toledo\n",
      "392 153 156 156\n",
      "Amelia_Vega\n",
      "392 154 166 166\n",
      "Alejandro_Toledo\n",
      "397 165 166 166\n",
      "Alejandro_Toledo\n",
      "397 165 166 166\n",
      "Alejandro_Toledo\n",
      "392 175 172 172\n",
      "Alejandro_Toledo\n",
      "385 186 178 178\n",
      "Abdullah_Gul\n",
      "370 191 173 173\n",
      "Amelia_Vega\n",
      "370 191 173 173\n",
      "Amelia_Vega\n",
      "347 188 179 179\n",
      "Amelia_Vega\n",
      "327 188 187 187\n",
      "Amelia_Vega\n",
      "314 186 186 186\n",
      "Alejandro_Toledo\n",
      "298 182 192 192\n",
      "Amelia_Vega\n",
      "303 188 186 186\n",
      "Amelia_Vega\n",
      "306 188 187 187\n",
      "Amelia_Vega\n",
      "307 187 190 190\n",
      "Amelia_Vega\n",
      "308 181 192 192\n",
      "Amelia_Vega\n",
      "308 182 191 191\n",
      "Amelia_Vega\n",
      "305 179 197 197\n",
      "Amelia_Vega\n",
      "305 179 197 197\n",
      "Amelia_Vega\n",
      "304 180 198 198\n",
      "Amelia_Vega\n",
      "301 182 201 201\n",
      "Amelia_Vega\n",
      "300 183 209 209\n",
      "Amelia_Vega\n",
      "303 189 203 203\n",
      "Amelia_Vega\n",
      "300 195 206 206\n",
      "Amelia_Vega\n",
      "300 195 206 206\n",
      "Amelia_Vega\n",
      "298 197 211 211\n",
      "Amelia_Vega\n",
      "297 197 209 209\n",
      "Amelia_Vega\n",
      "291 189 215 215\n",
      "Alejandro_Toledo\n",
      "287 181 213 213\n",
      "Amelia_Vega\n",
      "289 179 211 211\n",
      "Amelia_Vega\n",
      "289 179 211 211\n",
      "Amelia_Vega\n",
      "294 181 208 208\n",
      "Amelia_Vega\n",
      "297 181 207 207\n",
      "Amelia_Vega\n",
      "295 180 215 215\n",
      "Amelia_Vega\n",
      "299 181 212 212\n",
      "Amelia_Vega\n",
      "297 180 214 214\n",
      "Amelia_Vega\n",
      "297 180 214 214\n",
      "Amelia_Vega\n",
      "294 179 218 218\n",
      "Abdullah_Gul\n",
      "298 181 209 209\n",
      "Amelia_Vega\n",
      "298 177 210 210\n",
      "Amelia_Vega\n",
      "306 183 205 205\n",
      "Amelia_Vega\n",
      "303 180 214 214\n",
      "Amelia_Vega\n",
      "303 180 214 214\n",
      "Amelia_Vega\n",
      "301 177 213 213\n",
      "Amelia_Vega\n",
      "301 175 213 213\n",
      "Amelia_Vega\n",
      "300 172 218 218\n",
      "Abdullah_Gul\n",
      "301 171 221 221\n",
      "Amelia_Vega\n",
      "305 178 213 213\n",
      "Amelia_Vega\n",
      "309 181 210 210\n",
      "Amelia_Vega\n",
      "307 174 214 214\n",
      "Amelia_Vega\n",
      "307 174 214 214\n",
      "Amelia_Vega\n",
      "304 177 215 215\n",
      "Amelia_Vega\n",
      "302 172 219 219\n",
      "Abdullah_Gul\n",
      "302 173 217 217\n",
      "Amelia_Vega\n",
      "304 176 216 216\n",
      "Amelia_Vega\n",
      "313 181 208 208\n",
      "Amelia_Vega\n",
      "310 180 209 209\n",
      "Amelia_Vega\n",
      "304 179 209 209\n",
      "Amelia_Vega\n",
      "299 172 218 218\n",
      "Amelia_Vega\n",
      "307 172 211 211\n",
      "Amelia_Vega\n",
      "306 168 216 216\n",
      "Amelia_Vega\n",
      "313 172 212 212\n",
      "Amelia_Vega\n",
      "312 169 213 213\n",
      "Amelia_Vega\n",
      "311 169 214 214\n",
      "Amelia_Vega\n",
      "312 168 216 216\n",
      "Amelia_Vega\n",
      "313 168 215 215\n",
      "Amelia_Vega\n",
      "313 171 211 211\n",
      "Amelia_Vega\n",
      "313 171 211 211\n",
      "Amelia_Vega\n",
      "314 173 215 215\n",
      "Amelia_Vega\n",
      "316 171 211 211\n",
      "Amelia_Vega\n",
      "312 168 214 214\n",
      "Amelia_Vega\n",
      "312 166 218 218\n",
      "Abdullah_Gul\n",
      "312 165 219 219\n",
      "Amelia_Vega\n",
      "312 165 219 219\n",
      "Amelia_Vega\n",
      "313 164 221 221\n",
      "Amelia_Vega\n",
      "317 170 220 220\n",
      "Amelia_Vega\n",
      "324 173 213 213\n",
      "Amelia_Vega\n",
      "328 165 209 209\n",
      "Amelia_Vega\n",
      "319 163 216 216\n",
      "Amelia_Vega\n",
      "319 163 216 216\n",
      "Amelia_Vega\n",
      "320 170 214 214\n",
      "Amelia_Vega\n",
      "319 165 221 221\n",
      "Amelia_Vega\n",
      "330 168 216 216\n",
      "Alejandro_Toledo\n",
      "361 168 225 225\n",
      "Abdullah_Gul\n",
      "361 168 225 225\n",
      "Abdullah_Gul\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'cv2.VideoCapture' object has no attribute 'relase'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-aadb38fc1566>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestoyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'cv2.VideoCapture' object has no attribute 'relase'"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#cap.set(3,450)             video size\n",
    "#cap.set(4,650)             video size\n",
    "\n",
    "while True:\n",
    "    succes, vid= cap.read()\n",
    "    gray = cv2.cvtColor(vid, cv2.COLOR_BGR2GRAY)\n",
    "    facesquare = face_cascade.detectMultiScale(gray, 1.1, 7)\n",
    "    \n",
    "    for (x,y,w,h) in facesquare:       # squares where the face should be\n",
    "        #print(x,y,w,h) \n",
    "        si_gray = gray[y:y+h, x:x+w]   # square interest region\n",
    "        si_color = vid[y:y+h, x:x+w]\n",
    "        \n",
    "        \n",
    "        ids, pred = recognizer.predict(si_gray)     # prediction model loaded\n",
    "        \n",
    "        if pred >= 45:\n",
    "            print(names[ids])\n",
    "            name = names[ids]\n",
    "            cv2.putText(vid, name, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (230,230,230), 2, cv2.LINE_AA) # vid, id name, begin cords, font, , color, stroke, \n",
    "        \n",
    "        img_item = \"my_image4.png\"\n",
    "        cv2.imwrite(img_item, si_gray)\n",
    "                                           \n",
    "        cv2.rectangle(vid, (x,y), (x+w,y+h), (200,0,0), 2) # video, begin cords, end cords, color, line thickness\n",
    "        \n",
    "        smiles = smile_cascade.detectMultiScale(si_gray, 1.8, 20)\n",
    "        for (sx, sy, sw, sh) in smiles: \n",
    "            cv2.rectangle(si_color, (sx, sy), (sx + sw, sy + sh), (0, 0, 255), 2)\n",
    "        \n",
    "    cv2.imshow('Video',vid)\n",
    "    if cv2.waitKey(1) & 0xFF ==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.relase()        \n",
    "cv2.destoyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
